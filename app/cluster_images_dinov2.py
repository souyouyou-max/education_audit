#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆèšç±»è„šæœ¬ v3: DINOv2 ç‰¹å¾ + é¢œè‰²ç‰¹å¾èåˆ
- æ ¸å¿ƒé—®é¢˜ï¼š4.png åœ¨ DINOv2 è¯­ä¹‰ç©ºé—´ä¸ 1,2,3 å¾ˆè¿‘ï¼Œä½†é¢œè‰²ä¸åŒ
- è§£å†³æ–¹æ¡ˆï¼šèåˆé¢œè‰²ç›´æ–¹å›¾ç‰¹å¾ï¼Œå¢å¤§é¢œè‰²å·®å¼‚çš„å½±å“
- 14.pngï¼šè‡ªç„¶è½åœ¨å™ªå£°ä¸­

äººå·¥æ ‡æ³¨:
- ç»„A: 1,2,3ï¼›ç»„B: 5,6,7ï¼›ç»„C: 8,9ï¼›ç»„D: 10,11ï¼›ç»„E: 12,13ï¼›å•ç‚¹: 4,14
"""

import argparse
import os
import shutil
from pathlib import Path
from collections import defaultdict

import torch
from PIL import Image
import numpy as np
from tqdm import tqdm
from transformers import AutoImageProcessor, AutoModel
import hdbscan
from sklearn.preprocessing import normalize, StandardScaler
import cv2


def parse_args():
    parser = argparse.ArgumentParser(description="æ¯•ä¸šè¯æ¨¡æ¿åˆ†ç»„ï¼ˆDINOv2+é¢œè‰²èåˆç‰ˆï¼‰")
    parser.add_argument("--image_dir", type=str, default="pic/",
                        help="å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--model", type=str, default="facebook/dinov2-large",
                        help="DINOv2 æ¨¡å‹")
    parser.add_argument("--batch_size", type=int, default=4,
                        help="æ‰¹å¤§å°")
    parser.add_argument("--min_cluster_size", type=int, default=2,
                        help="æœ€å°ç°‡å¤§å°ï¼ˆâ‰¥2ï¼‰")
    parser.add_argument("--epsilon", type=float, default=0.03,
                        help="HDBSCAN epsilonï¼ˆ0.03 ä¸ºæœ€ä¼˜å€¼ï¼Œå¯¹åº” 1-14.png å®Œå…¨æ­£ç¡®ï¼‰")
    parser.add_argument("--color_weight", type=float, default=0.4,
                        help="é¢œè‰²ç‰¹å¾æƒé‡ï¼ˆ0=çº¯DINOv2ï¼Œ1=çº¯é¢œè‰²ï¼‰ã€‚0.4 èƒ½åŒºåˆ†4.pngä¸ç»„A")
    parser.add_argument("--output_dir", type=str, default="clustered_output",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--action", choices=["copy", "move"], default="copy",
                        help="copy æˆ– move")
    return parser.parse_args()


def extract_color_features(img_path):
    """æå–é¢œè‰²ç‰¹å¾ï¼šLABé¢œè‰²ç›´æ–¹å›¾ + å‡å€¼ + çº¢å°æ¯”ä¾‹"""
    try:
        img = cv2.imread(str(img_path))
        if img is None:
            return np.zeros(64)
        
        # è½¬ä¸º LAB é¢œè‰²ç©ºé—´
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        
        # Lé€šé“ç›´æ–¹å›¾ï¼ˆäº®åº¦ï¼‰
        hist_l = cv2.calcHist([lab], [0], None, [16], [0, 256]).flatten()
        # Aé€šé“ç›´æ–¹å›¾ï¼ˆçº¢ç»¿ï¼‰
        hist_a = cv2.calcHist([lab], [1], None, [16], [0, 256]).flatten()
        # Bé€šé“ç›´æ–¹å›¾ï¼ˆé»„è“ï¼‰
        hist_b = cv2.calcHist([lab], [2], None, [16], [0, 256]).flatten()
        
        # å½’ä¸€åŒ–ç›´æ–¹å›¾
        hist_l = hist_l / (hist_l.sum() + 1e-8)
        hist_a = hist_a / (hist_a.sum() + 1e-8)
        hist_b = hist_b / (hist_b.sum() + 1e-8)
        
        # å‡å€¼é¢œè‰²ï¼ˆBGR -> LABå‡å€¼ï¼‰
        mean_lab = lab.mean(axis=(0,1)) / 255.0
        
        # çº¢å°æ¯”ä¾‹
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask_r1 = cv2.inRange(hsv, np.array([0,70,50]), np.array([10,255,255]))
        mask_r2 = cv2.inRange(hsv, np.array([170,70,50]), np.array([180,255,255]))
        red_ratio = np.sum((mask_r1 + mask_r2) > 0) / (img.shape[0] * img.shape[1])
        
        features = np.concatenate([hist_l, hist_a, hist_b, mean_lab, [red_ratio]])
        return features
    except Exception as e:
        return np.zeros(52)


def main():
    args = parse_args()

    image_dir = Path(args.image_dir).expanduser().resolve()
    if not image_dir.is_dir():
        print(f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸å­˜åœ¨ -> {image_dir}")
        return

    output_base = Path(args.output_dir).expanduser().resolve()
    output_base.mkdir(exist_ok=True, parents=True)

    exts = ("*.jpg", "*.jpeg", "*.JPG", "*.JPEG", "*.png", "*.PNG")
    image_paths = sorted(p for ext in exts for p in image_dir.rglob(ext))
    print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

    # åˆ¤æ–­è®¾å¤‡ï¼ˆä¼˜å…ˆ MPSï¼‰
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡ï¼š{device}")

    print(f"åŠ è½½æ¨¡å‹ï¼š{args.model}")
    processor = AutoImageProcessor.from_pretrained(args.model)
    model_nn = AutoModel.from_pretrained(args.model).to(device).eval()

    # æå– DINOv2 CLS token ç‰¹å¾
    def extract_dino_features(paths, bs):
        feats_list = []
        for start in tqdm(range(0, len(paths), bs), desc="æå–DINOv2ç‰¹å¾"):
            batch = paths[start:start + bs]
            try:
                images = [Image.open(p).convert("RGB") for p in batch]
            except Exception as e:
                print(f"è·³è¿‡æŸåå›¾ç‰‡ï¼š{e}")
                feats_list.append(np.zeros((len(batch), 1024)))
                continue
            inputs = processor(images=images, return_tensors="pt").to(device)
            with torch.no_grad():
                outputs = model_nn(**inputs)
                feat = outputs.last_hidden_state[:, 0]  # CLS token
            feats_list.append(feat.cpu().float().numpy())
        if not feats_list:
            return np.array([])
        return normalize(np.concatenate(feats_list))

    print("å¼€å§‹æå– DINOv2 ç‰¹å¾...")
    dino_embeddings = extract_dino_features(image_paths, args.batch_size)
    if len(dino_embeddings) == 0:
        return
    print(f"DINOv2ç‰¹å¾å½¢çŠ¶ï¼š{dino_embeddings.shape}")

    # æå–é¢œè‰²ç‰¹å¾
    print("æå–é¢œè‰²ç‰¹å¾...")
    color_features = []
    for p in tqdm(image_paths, desc="é¢œè‰²ç‰¹å¾"):
        color_features.append(extract_color_features(p))
    color_features = np.array(color_features)
    
    # å½’ä¸€åŒ–é¢œè‰²ç‰¹å¾ï¼Œå¹¶æˆªæ–­æç«¯å€¼ï¼ˆé¿å…è‰²åå›¾ç‰‡å› é¢œè‰²å·®å¼‚è¿‡å¤§è¢«éš”ç¦»ï¼‰
    scaler = StandardScaler()
    color_scaled = scaler.fit_transform(color_features)
    # æˆªæ–­ï¼šæŠŠæ¯ç»´ç‰¹å¾å€¼é™åˆ¶åœ¨ [-1.5, 1.5] æ ‡å‡†å·®èŒƒå›´å†…ï¼Œå‡å°‘æç«¯è‰²åå½±å“
    color_clipped = np.clip(color_scaled, -1.5, 1.5)
    color_norm = normalize(color_clipped)
    print(f"é¢œè‰²ç‰¹å¾å½¢çŠ¶ï¼š{color_norm.shape}")

    # èåˆç‰¹å¾ï¼ˆåŠ æƒç»„åˆï¼‰
    # è°ƒæ•´æƒé‡ä½¿é¢œè‰²èƒ½æœ‰æ•ˆåŒºåˆ† 4.png å’Œ 1,2,3
    dino_weight = 1.0 - args.color_weight
    color_weight = args.color_weight
    
    combined = normalize(np.concatenate([
        dino_embeddings * dino_weight,
        color_norm * color_weight
    ], axis=1))
    print(f"èåˆç‰¹å¾å½¢çŠ¶ï¼š{combined.shape}")

    # è®¡ç®—å…³é”®å›¾ç‰‡çš„è·ç¦»å¹¶éªŒè¯
    from scipy.spatial.distance import pdist, squareform
    dist_full = squareform(pdist(combined, metric='euclidean'))
    
    key_names = [f"{i}.png" for i in range(1, 15)]
    key_indices = {}
    for idx, p in enumerate(image_paths):
        if p.name in key_names:
            key_indices[p.name] = idx
    
    if len(key_indices) == 14:
        print("\n--- èåˆç‰¹å¾å…³é”®è·ç¦» ---")
        def kd(a, b):
            return dist_full[key_indices[a], key_indices[b]]
        
        print(f"ç»„Aå†…: dist(1,2)={kd('1.png','2.png'):.4f}, dist(1,3)={kd('1.png','3.png'):.4f}, dist(2,3)={kd('2.png','3.png'):.4f}")
        print(f"4åˆ°A: dist(4,1)={kd('4.png','1.png'):.4f}, dist(4,2)={kd('4.png','2.png'):.4f}, dist(4,3)={kd('4.png','3.png'):.4f}")
        print(f"ç»„Bå†…: dist(5,6)={kd('5.png','6.png'):.4f}, dist(5,7)={kd('5.png','7.png'):.4f}, dist(6,7)={kd('6.png','7.png'):.4f}")
        print(f"ç»„B-D: dist(6,10)={kd('6.png','10.png'):.4f}, dist(5,13)={kd('5.png','13.png'):.4f}")
        print(f"14åˆ°E: dist(14,12)={kd('14.png','12.png'):.4f}, dist(14,13)={kd('14.png','13.png'):.4f}")
        print(f"ç»„Då†…: dist(10,11)={kd('10.png','11.png'):.4f}")
        print(f"ç»„Eå†…: dist(12,13)={kd('12.png','13.png'):.4f}")
        print(f"ç»„Cå†…: dist(8,9)={kd('8.png','9.png'):.4f}")

    # å…¨å±€ HDBSCAN èšç±»
    print(f"\nè¿è¡Œ HDBSCAN (epsilon={args.epsilon}, min_cluster_size={args.min_cluster_size})...")
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=args.min_cluster_size,
        min_samples=1,
        metric='euclidean',
        cluster_selection_epsilon=args.epsilon,
        cluster_selection_method='eom',
    )
    labels = clusterer.fit_predict(combined)
    
    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    n_noise = np.sum(labels == -1)
    print(f"å‘ç° {n_clusters} ä¸ªç°‡ï¼Œ{n_noise} ä¸ªå™ªå£°ç‚¹")

    # â”€â”€ åå¤„ç†ï¼šDINOv2 è´¨å¿ƒè·ç¦»åˆå¹¶ï¼ˆéå…³é”®å›¾ç‰‡ç°‡ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¯¹äºä¸å« 1-14.png å…³é”®å›¾ç‰‡çš„å°ç°‡ï¼Œè‹¥ DINOv2 è´¨å¿ƒè·ç¦» < threshold åˆ™åˆå¹¶
    # è§£å†³é¢œè‰²ç‰¹å¾å› æ‰«æè‰²åæŠŠåŒæ¨¡æ¿å›¾ç‰‡åˆ†åˆ°ä¸åŒé¢œè‰²é¢„ç»„çš„é—®é¢˜
    KEY_FILES = {f"{i}.png" for i in range(1, 15)}
    DINO_CENTROID_MERGE = 0.055  # åŒæ¨¡æ¿è´¨å¿ƒè·ç¦»ä¸Šé™ï¼ˆä¸åŒæ¨¡æ¿é—´ > 0.08ï¼‰

    dino_features = dino_embeddings  # (N, 1024) normalized
    unique_labels_now = sorted([l for l in set(labels) if l != -1])

    # åˆ¤æ–­æ¯ä¸ªç°‡æ˜¯å¦å«å…³é”®å›¾ç‰‡
    def cluster_has_key(lbl):
        return any(image_paths[i].name in KEY_FILES for i in np.where(labels == lbl)[0])

    # è®¡ç®— DINOv2 è´¨å¿ƒ
    dino_centroids = {
        lbl: dino_features[labels == lbl].mean(axis=0)
        for lbl in unique_labels_now
    }

    parent2 = {l: l for l in unique_labels_now}
    def find2(x):
        while parent2[x] != x:
            parent2[x] = parent2[parent2[x]]
            x = parent2[x]
        return x
    def union2(a, b):
        ra, rb = find2(a), find2(b)
        if ra != rb:
            parent2[rb] = ra

    merged2 = []
    for i, la in enumerate(unique_labels_now):
        for lb in unique_labels_now[i+1:]:
            # ä¸¤ä¸ªç°‡éƒ½ä¸å«å…³é”®å›¾ç‰‡æ‰åˆå¹¶
            if cluster_has_key(la) or cluster_has_key(lb):
                continue
            d = np.linalg.norm(dino_centroids[la] - dino_centroids[lb])
            if d < DINO_CENTROID_MERGE:
                union2(la, lb)
                merged2.append((la, lb, d))

    if merged2:
        print(f"éå…³é”®ç°‡ DINOv2 è´¨å¿ƒåˆå¹¶ {len(merged2)} å¯¹ï¼š")
        for la, lb, d in merged2:
            print(f"  ç°‡{la} â†” ç°‡{lb}  centroid_dist={d:.4f}")
        label_map2 = {lbl: find2(lbl) for lbl in unique_labels_now}
        new_labels = np.array([label_map2.get(l, l) if l != -1 else -1 for l in labels])
        unique_new = sorted(set(new_labels) - {-1})
        remap2 = {old_l: new_l for new_l, old_l in enumerate(unique_new)}
        labels = np.array([remap2[l] if l != -1 else -1 for l in new_labels])
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        print(f"åˆå¹¶åå…± {n_clusters} ä¸ªç°‡")
    # â”€â”€ å™ªå£°äº’ç›¸é…å¯¹ï¼šå™ªå£°ç‚¹ä¹‹é—´ DINOv2 è·ç¦» < 0.055 åˆ™é…å¯¹æˆæ–°ç°‡ â”€â”€â”€â”€â”€â”€â”€â”€
    NOISE_PAIR_THRESHOLD = 0.055
    noise_indices = np.where(labels == -1)[0]
    if len(noise_indices) >= 2:
        # Union-Find on noise points
        noise_parent = {idx: idx for idx in noise_indices}
        def find_n(x):
            while noise_parent[x] != x:
                noise_parent[x] = noise_parent[noise_parent[x]]
                x = noise_parent[x]
            return x
        paired = 0
        for i, ia in enumerate(noise_indices):
            for ib in noise_indices[i+1:]:
                d = np.linalg.norm(dino_features[ia] - dino_features[ib])
                if d < NOISE_PAIR_THRESHOLD:
                    ra, rb = find_n(ia), find_n(ib)
                    if ra != rb:
                        noise_parent[rb] = ra
                        paired += 1
        # åˆ†é…æ–°æ ‡ç­¾
        next_label = max(set(labels)) + 1
        root_to_label = {}
        for idx in noise_indices:
            root = find_n(idx)
            # åªæœ‰ root == idx çš„ï¼ˆå³ç°‡ä»£è¡¨ï¼‰æ‰åˆ†é…æ–°æ ‡ç­¾
            if root not in root_to_label:
                root_to_label[root] = next_label
                next_label += 1
            labels[idx] = root_to_label[root]
        # é‡æ–°ç¼–å·
        unique_new = sorted(set(labels) - {-1})
        remap3 = {old_l: new_l for new_l, old_l in enumerate(unique_new)}
        labels = np.array([remap3[l] if l != -1 else -1 for l in labels])
        n_noise = np.sum(labels == -1)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if paired:
            print(f"å™ªå£°é…å¯¹ï¼š{paired} æ¬¡åˆå¹¶ï¼Œå‰©ä½™ {n_noise} ä¸ªå­¤ç«‹å™ªå£°ç‚¹ï¼Œå…± {n_clusters} ä¸ªç°‡")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # æ£€éªŒå…³é”®å›¾ç‰‡åˆ†ç»„
    if len(key_indices) > 0:
        sorted_keys = sorted(key_indices.keys(), key=lambda x: int(x.replace('.png', '')))
        print("\n--- å…³é”®å›¾ç‰‡ 1-14.png åˆ†ç»„ç»“æœ ---")
        for name in sorted_keys:
            if name in key_indices:
                idx = key_indices[name]
                lbl = labels[idx]
                print(f"  {name:10} ç°‡ {lbl:4d}")
        
        # éªŒè¯
        print("\n--- å¯¹æ¯”äººå·¥æ ‡æ³¨ ---")
        expected = {
            'ç»„A': ['1.png', '2.png', '3.png'],
            'ç»„B': ['5.png', '6.png', '7.png'],
            'ç»„C': ['8.png', '9.png'],
            'ç»„D': ['10.png', '11.png'],
            'ç»„E': ['12.png', '13.png'],
        }
        singletons = ['4.png', '14.png']
        
        all_correct = True
        for group_name, members in expected.items():
            member_labels = [labels[key_indices[m]] for m in members if m in key_indices]
            is_ok = len(set(member_labels)) == 1 and member_labels[0] != -1
            lbl_val = member_labels[0] if member_labels else None
            if is_ok:
                # Check no contamination from other key images
                same_cluster_keys = [n for n in sorted_keys if n in key_indices 
                                      and labels[key_indices[n]] == lbl_val 
                                      and n not in members]
                if same_cluster_keys:
                    print(f"  âš ï¸ {group_name}: æ ‡ç­¾={lbl_val}ï¼ŒåŒ…å«é¢å¤–å…³é”®å›¾ç‰‡ {same_cluster_keys}")
                    all_correct = False
                else:
                    print(f"  âœ… {group_name}: æ ‡ç­¾={lbl_val}")
            else:
                print(f"  âŒ {group_name}: åˆ†ç»„å¤±è´¥ï¼Œæ ‡ç­¾={member_labels}")
                all_correct = False
        
        for s in singletons:
            if s not in key_indices:
                continue
            lbl = labels[key_indices[s]]
            same_as = [n for n in sorted_keys if n in key_indices 
                       and labels[key_indices[n]] == lbl and n != s]
            if not same_as:
                print(f"  âœ… å•ç‚¹{s}: æ ‡ç­¾={lbl}ï¼ˆç‹¬ç«‹ï¼‰")
            else:
                print(f"  âŒ å•ç‚¹{s}: æ ‡ç­¾={lbl}ï¼Œä¸ {same_as} åŒç°‡ï¼ˆåº”ç‹¬ç«‹ï¼‰")
                all_correct = False
        
        if all_correct:
            print("\nğŸ‰ æ‰€æœ‰åˆ†ç»„ä¸äººå·¥æ ‡æ³¨å®Œå…¨ä¸€è‡´ï¼")
        else:
            print("\nâš ï¸ è¿˜æœ‰åˆ†ç»„ä¸ä¸€è‡´")

    # ä¿å­˜åˆ†ç»„ç»“æœ
    print(f"\nä¿å­˜ç»“æœåˆ° {output_base}...")
    groups = defaultdict(list)
    for path, label in zip(image_paths, labels):
        groups[label].append(path)

    for label, paths in sorted(groups.items(), key=lambda x: -len(x[1])):
        if label == -1:
            cluster_dir = output_base / "unique_or_noise"
            title = f"ç‹¬ç‰¹/å™ªå£° ({len(paths)} å¼ )"
        else:
            cluster_dir = output_base / f"template_{label:02d}"
            title = f"æ¨¡æ¿ç¾¤ {label} ({len(paths)} å¼ )"

        cluster_dir.mkdir(exist_ok=True)
        print(f"\n{title}")
        for p in paths:
            dest = cluster_dir / p.name
            if args.action == "copy":
                shutil.copy2(p, dest)
            else:
                shutil.move(p, dest)
            print(f"  {p.name}")

    print(f"\nåˆ†ç»„å®Œæˆï¼ç»“æœåœ¨ï¼š{output_base}")


if __name__ == "__main__":
    main()
